"""
Gemini API å®¢æˆ¶ç«¯æ¨¡çµ„ - è™•ç†èˆ‡ Google Gemini API çš„æ‰€æœ‰äº¤äº’
"""

import json
import logging
import asyncio
from typing import List, Optional, Dict, Any, Tuple
import google.generativeai as genai

from .config import PROMPT_TEMPLATE


class GeminiClient:
    """Gemini API å®¢æˆ¶ç«¯é¡åˆ¥"""
    
    def __init__(self, api_key: str, model_name: str = "gemini-1.5-pro-latest"):
        """åˆå§‹åŒ–Geminiå®¢æˆ¶ç«¯
        
        Args:
            api_key: Gemini API é‡‘é‘°
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç¨±
        """
        self.api_key = api_key
        self.model_name = model_name
        self.model = None
        self.logger = logging.getLogger(__name__)
        
        if api_key:
            self._configure_gemini(api_key, model_name)
    
    def _configure_gemini(self, api_key: str, model_name: str) -> bool:
        """è¨­å®š Gemini API é‡‘é‘°ä¸¦åˆå§‹åŒ–æ¨¡å‹"""
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(model_name)
            return True
        except Exception as e:
            self.logger.error(f"è¨­å®š Gemini API é‡‘é‘°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    async def grade_responses_batch(self, texts: List[str], rubric: str, question_id: int) -> tuple:
        """æ‰¹æ¬¡è©•åˆ†å­¸ç”Ÿå›ç­”
        
        Args:
            texts: å­¸ç”Ÿå›ç­”æ–‡æœ¬åˆ—è¡¨
            rubric: è©•åˆ†æ¨™æº–
            question_id: å•é¡Œç·¨è™Ÿ
            
        Returns:
            tuple: (åˆ†æ•¸åˆ—è¡¨, AIé¢¨éšªåˆ—è¡¨)
        """
        if not self.model:
            raise ValueError("Geminiæ¨¡å‹æœªåˆå§‹åŒ–")
        
        scores = []
        ai_risks = []
        
        for text in texts:
            try:
                score, ai_risk = await self._grade_single_response(text, rubric, question_id)
                scores.append(score)
                ai_risks.append(ai_risk)
            except Exception as e:
                self.logger.error(f"è©•åˆ†å–®å€‹å›ç­”å¤±æ•—: {e}")
                scores.append(0.0)
                ai_risks.append(0)
        
        return scores, ai_risks
    
    async def _grade_single_response(self, text: str, rubric: str, question_id: int) -> tuple:
        """è©•åˆ†å–®å€‹å­¸ç”Ÿå›ç­”ï¼ŒåŒæ™‚è¿”å›åˆ†æ•¸å’ŒAIé¢¨éšª"""
        try:
            # æ§‹å»ºæ­£ç¢ºçš„ prompt
            grade_block = f"Then score this answer based on the rubric, returning an integer from 0â€‘10.\n\nRubric:\n{rubric}"
            question = f"Question {question_id}"
            
            prompt = PROMPT_TEMPLATE.format(
                grade_block=grade_block,
                question=question,
                answer=text
            )
            
            self.logger.info(f"ğŸ¤– ç™¼é€çµ¦ Gemini çš„ Prompt (Q{question_id}):")
            self.logger.info(f"ğŸ“ å­¸ç”Ÿå›ç­”: {text[:100]}...")
            
            response = await asyncio.to_thread(
                self.model.generate_content,
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=150,
                    temperature=0.1,
                    candidate_count=1
                )
            )
            
            # æª¢æŸ¥å›æ‡‰ç‹€æ…‹
            if not response.candidates or not response.candidates[0].content.parts:
                finish_reason = response.candidates[0].finish_reason if response.candidates else "NO_CANDIDATES"
                self.logger.warning(f"ğŸš¨ APIå›æ‡‰è¢«éæ¿¾ (finish_reason: {finish_reason})ï¼Œä½¿ç”¨æœ¬åœ°è©•åˆ†")
                # è¿”å›æœ¬åœ°è©•åˆ†çµæœ
                local_score = self._estimate_local_score(text)
                return local_score, 0  # AIé¢¨éšªè¨­ç‚º0ï¼ˆå› ç‚ºAPIéæ¿¾ä¸èƒ½åˆ¤æ–·ï¼‰
            
            # è¨˜éŒ„ AI å›æ‡‰
            response_text = response.text.strip()
            self.logger.info(f"ğŸ¤– Gemini å›æ‡‰ (Q{question_id}): {response_text}")
            
            # è§£æå›æ‡‰ä¸­çš„åˆ†æ•¸å’ŒAIé¢¨éšª
            score, ai_risk = self._extract_score_and_ai_risk_from_response(response_text)
            self.logger.info(f"ğŸ“Š è§£æå‡ºçš„åˆ†æ•¸ (Q{question_id}): {score}")
            self.logger.info(f"ğŸ” è§£æå‡ºçš„AIé¢¨éšª (Q{question_id}): {ai_risk}")
            
            return score, ai_risk
            
        except Exception as e:
            self.logger.error(f"è©•åˆ†å¤±æ•—: {e}")
            # ä½¿ç”¨æœ¬åœ°è©•åˆ†ä½œç‚ºå¾Œå‚™
            local_score = self._estimate_local_score(text)
            self.logger.info(f"ğŸ’» ä½¿ç”¨æœ¬åœ°è©•åˆ†: {local_score}")
            return local_score, 0
    
    def _extract_score_from_response(self, response_text: str) -> float:
        """å¾Geminiå›æ‡‰ä¸­æå–åˆ†æ•¸"""
        import re
        
        # å°‹æ‰¾ JSON æ ¼å¼çš„åˆ†æ•¸
        json_match = re.search(r'\{.*?"score":\s*([0-9.]+).*?\}', response_text, re.DOTALL)
        if json_match:
            try:
                return float(json_match.group(1))
            except ValueError:
                pass
        
        # å°‹æ‰¾æ•¸å­—æ ¼å¼çš„åˆ†æ•¸
        number_matches = re.findall(r'(?:åˆ†æ•¸|score|å¾—åˆ†).*?([0-9.]+)', response_text, re.IGNORECASE)
        if number_matches:
            try:
                return float(number_matches[0])
            except ValueError:
                pass
        
        # å°‹æ‰¾ä»»ä½•æ•¸å­—
        all_numbers = re.findall(r'\b([0-9.]+)\b', response_text)
        if all_numbers:
            try:
                score = float(all_numbers[0])
                return min(score, 10.0)  # é™åˆ¶æœ€é«˜åˆ†ç‚º10åˆ†
            except ValueError:
                pass
        
        return 0.0
    
    def _extract_score_and_ai_risk_from_response(self, response_text: str) -> tuple:
        """å¾Geminiå›æ‡‰ä¸­æå–åˆ†æ•¸å’ŒAIé¢¨éšª"""
        import re
        import json
        
        score = 0.0
        ai_risk = 0
        
        try:
            # å˜—è©¦è§£æJSONæ ¼å¼
            json_match = re.search(r'\{.*?"ai_risk".*?"score".*?\}|\{.*?"score".*?"ai_risk".*?\}', response_text, re.DOTALL)
            if json_match:
                json_data = json.loads(json_match.group(0))
                ai_risk = int(json_data.get('ai_risk', 0))
                score = float(json_data.get('score', 0))
                return score, ai_risk
        except (json.JSONDecodeError, ValueError):
            pass
        
        # å¦‚æœJSONè§£æå¤±æ•—ï¼Œåˆ†åˆ¥æå–æ•¸å­—
        ai_risk_match = re.search(r'"ai_risk":\s*(\d+)', response_text)
        if ai_risk_match:
            ai_risk = int(ai_risk_match.group(1))
        
        score_match = re.search(r'"score":\s*([0-9.]+)', response_text)
        if score_match:
            score = float(score_match.group(1))
        elif not score_match:
            # å°‹æ‰¾ä»»ä½•æ•¸å­—ä½œç‚ºåˆ†æ•¸
            all_numbers = re.findall(r'\b([0-9.]+)\b', response_text)
            if all_numbers:
                score = float(all_numbers[-1])  # å–æœ€å¾Œä¸€å€‹æ•¸å­—
                score = min(score, 10.0)  # é™åˆ¶æœ€é«˜åˆ†ç‚º10åˆ†
        
        return score, ai_risk
    
    def _estimate_local_score(self, text: str) -> float:
        """æœ¬åœ°è©•åˆ†ä¼°ç®—ï¼ˆå¾analyzer.pyè¤‡è£½ï¼‰"""
        if not text.strip():
            return 0.0
        
        text_clean = text.strip().lower()
        
        # åŸºæ–¼æ–‡æœ¬é•·åº¦çš„åŸºç¤åˆ†æ•¸
        word_count = len(text_clean.split())
        if word_count < 20:
            base_score = 2.0
        elif word_count < 50:
            base_score = 4.0
        elif word_count < 100:
            base_score = 6.0
        elif word_count < 200:
            base_score = 7.0
        else:
            base_score = 8.0
        
        # æª¢æŸ¥æ˜¯å¦æœ‰çµæ§‹åŒ–å›ç­”
        structure_bonus = 0.0
        if any(marker in text for marker in ['1.', '2.', '3.', 'â€¢', '-', 'advantage', 'disadvantage']):
            structure_bonus = 0.5
        
        final_score = min(base_score + structure_bonus, 10.0)
        return max(final_score, 1.0) if text.strip() else 0.0


# ä¿æŒå‘å¾Œç›¸å®¹çš„å‡½æ•¸æ¥å£
def configure_gemini(api_key: str, model_name: str = "gemini-1.5-pro-latest") -> bool:
    """å‘å¾Œç›¸å®¹çš„é…ç½®å‡½æ•¸"""
    try:
        client = GeminiClient(api_key, model_name)
        return client.model is not None
    except Exception:
        return False
        return True
    except Exception as e:
        logging.error(f"è¨­å®š Gemini API é‡‘é‘°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

async def gemini_eval(question: str, rubric: str, answer: str, need_score: bool) -> Tuple[int, float]:
    """éåŒæ­¥å‘¼å« Gemini API é€²è¡Œ AI é¢¨æ ¼åˆ†æèˆ‡è©•åˆ†"""
    global gmodel
    
    if gmodel is None:
        raise ValueError("Gemini æ¨¡å‹å°šæœªåˆå§‹åŒ–")
    
    if need_score:
        grade_block = f"Then score this answer based on the rubric, returning an integer from 0â€‘10.\n\nRubric:\n{rubric}"
    else:
        grade_block = "Do NOT provide a score, just return 'score': null."
        
    prompt = PROMPT_TEMPLATE.format(
        grade_block=grade_block,
        question=question,
        answer=answer
    )
    
    try:
        response = await gmodel.generate_content_async(prompt)
        
        if not response.text:
            logging.warning("Gemini API å›æ‡‰ç‚ºç©º")
            return 0, None if not need_score else 0
            
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå– JSON
        import re
        json_pattern = r'\{[^{}]*"ai_risk"\s*:\s*\d+[^{}]*\}'
        matches = re.findall(json_pattern, response.text)
        
        if matches:
            json_str = matches[0]
        else:
            # å¦‚æœæ‰¾ä¸åˆ°å®Œæ•´çš„ JSONï¼Œå˜—è©¦è§£ææ•´å€‹å›æ‡‰
            json_str = response.text.strip()
            
        try:
            result = json.loads(json_str)
            ai_risk = result.get("ai_risk", 0)
            score = result.get("score") if need_score else None
            return ai_risk, score
        except json.JSONDecodeError:
            # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œå˜—è©¦æå–æ•¸å­—
            ai_risk_match = re.search(r'"ai_risk"\s*:\s*(\d+)', response.text)
            score_match = re.search(r'"score"\s*:\s*(\d+)', response.text) if need_score else None
            
            ai_risk = int(ai_risk_match.group(1)) if ai_risk_match else 0
            score = int(score_match.group(1)) if score_match and need_score else None
            
            return ai_risk, score
            
    except Exception as e:
        logging.error(f"Gemini API å‘¼å«å¤±æ•—: {e}")
        return 0, None if not need_score else 0
