"""
ç›¸ä¼¼åº¦æª¢æ¸¬æ¨¡çµ„ - çµ±ä¸€çš„ç›¸ä¼¼åº¦æª¢æ¸¬æ¥å£
"""

import logging
import numpy as np
from typing import List, Tuple, Optional, Dict, Any
import google.generativeai as genai
from sklearn.metrics.pairwise import cosine_similarity

from .config import SIMILARITY_THRESHOLDS, DO_SIMILARITY_CHECK


class SimilarityDetector:
    """ç›¸ä¼¼åº¦æª¢æ¸¬å™¨é¡åˆ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç›¸ä¼¼åº¦æª¢æ¸¬å™¨"""
        self.logger = logging.getLogger(__name__)
        self.thresholds = SIMILARITY_THRESHOLDS
    
    async def calculate_genai_similarity(self, texts: List[str], names: List[str] = None, 
                                       gemini_client=None) -> Dict[str, Any]:
        """ä½¿ç”¨GenAIè¨ˆç®—ç›¸ä¼¼åº¦
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            names: å§“ååˆ—è¡¨
            gemini_client: Geminiå®¢æˆ¶ç«¯å¯¦ä¾‹
            
        Returns:
            Dict: ç›¸ä¼¼åº¦çµæœ
        """
        try:
            if not gemini_client or not gemini_client.model:
                raise ValueError("Geminiå®¢æˆ¶ç«¯æœªæä¾›æˆ–æœªåˆå§‹åŒ–")
            
            # ä½¿ç”¨GoogleåµŒå…¥API
            processed_texts = [t.strip() if t and t.strip() else " " for t in texts]
            
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=processed_texts,
                task_type="RETRIEVAL_DOCUMENT"
            )
            
            embs = np.array(result['embedding'])
            similarity_matrix = cosine_similarity(embs)
            
            # è¨ˆç®—ç›¸ä¼¼åº¦æ¨™è¨˜
            flags = self._calculate_flags_from_matrix(similarity_matrix, texts)
            
            # è¨˜éŒ„ç›¸ä¼¼åº¦æª¢æ¸¬çµæœ
            self.logger.info(f"ğŸ” GenAI ç›¸ä¼¼åº¦æª¢æ¸¬çµæœ:")
            for i, flag in enumerate(flags):
                if flag > 0:
                    max_sim = max(similarity_matrix[i][j] for j in range(len(texts)) if i != j) if len(texts) > 1 else 0
                    self.logger.info(f"  å­¸ç”Ÿ {i+1}: æ¨™è¨˜={flag}, æœ€é«˜ç›¸ä¼¼åº¦={max_sim:.3f}")
            
            return {
                'flags': flags,
                'matrix': similarity_matrix,
                'info': {
                    'method': 'genai',
                    'model': 'text-embedding-004',
                    'status': 'success'
                }
            }
            
        except Exception as e:
            self.logger.error(f"GenAIç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            # é™ç´šåˆ°æœ¬åœ°æ–¹æ³•
            return self.calculate_local_similarity(texts, names)
    
    def calculate_local_similarity(self, texts: List[str], names: List[str] = None) -> Dict[str, Any]:
        """ä½¿ç”¨æœ¬åœ°ç®—æ³•è¨ˆç®—ç›¸ä¼¼åº¦
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            names: å§“ååˆ—è¡¨
            
        Returns:
            Dict: ç›¸ä¼¼åº¦çµæœ
        """
        try:
            from .alternative_similarity_methods import calculate_advanced_similarity
            
            n = len(texts)
            similarity_matrix = np.zeros((n, n))
            
            # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
            for i in range(n):
                for j in range(n):
                    if i != j and texts[i].strip() and texts[j].strip():
                        similarity = calculate_advanced_similarity(texts[i], texts[j])
                        similarity_matrix[i][j] = similarity
                    elif i == j:
                        similarity_matrix[i][j] = 1.0
            
            # è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸ (0-100)
            scores = self._calculate_scores_from_matrix(similarity_matrix, texts)
            
            # è¨˜éŒ„æœ¬åœ°ç›¸ä¼¼åº¦æª¢æ¸¬çµæœ
            self.logger.info(f"ğŸ” æœ¬åœ°ç›¸ä¼¼åº¦æª¢æ¸¬çµæœ:")
            for i, score in enumerate(scores):
                if score > 0:
                    max_sim = max(similarity_matrix[i][j] for j in range(len(texts)) if i != j) if len(texts) > 1 else 0
                    self.logger.info(f"  å­¸ç”Ÿ {i+1}: ç›¸ä¼¼åº¦åˆ†æ•¸={score}, æœ€é«˜ç›¸ä¼¼åº¦={max_sim:.3f}")
            
            return {
                'scores': scores,
                'matrix': similarity_matrix,
                'info': {
                    'method': 'local',
                    'algorithms': 'advanced_multi_algorithm',
                    'status': 'success'
                }
            }
            
        except Exception as e:
            self.logger.error(f"æœ¬åœ°ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return {
                'scores': [0] * len(texts),
                'matrix': None,
                'info': {
                    'method': 'error',
                    'status': 'failed',
                    'error': str(e)
                }
            }
    
    def _calculate_flags_from_matrix(self, similarity_matrix: np.ndarray, texts: List[str]) -> List[int]:
        """å¾ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—æ¨™è¨˜"""
        n = len(texts)
        flags = [0] * n
        
        hi_threshold = self.thresholds.get('high', 0.85)
        mid_threshold = self.thresholds.get('medium', 0.7)
        min_length = self.thresholds.get('min_length', 50)
        
        for i in range(n):
            # æª¢æŸ¥æ–‡æœ¬é•·åº¦
            if len(texts[i].strip()) < min_length:
                continue
            
            max_similarity = 0.0
            for j in range(n):
                if i != j:
                    max_similarity = max(max_similarity, similarity_matrix[i][j])
            
            # è¨­å®šæ¨™è¨˜
            if max_similarity >= hi_threshold:
                flags[i] = 2  # é«˜åº¦ç›¸ä¼¼
            elif max_similarity >= mid_threshold:
                flags[i] = 1  # ä¸­ç­‰ç›¸ä¼¼
        
        return flags
    
    def _calculate_scores_from_matrix(self, similarity_matrix: np.ndarray, texts: List[str]) -> List[int]:
        """å¾ç›¸ä¼¼åº¦çŸ©é™£è¨ˆç®—0-100åˆ†çš„ç›¸ä¼¼åº¦åˆ†æ•¸"""
        n = len(texts)
        scores = [0] * n
        
        min_length = self.thresholds.get('min_length', 50)
        
        for i in range(n):
            # æª¢æŸ¥æ–‡æœ¬é•·åº¦
            if len(texts[i].strip()) < min_length:
                scores[i] = 0
                continue
            
            max_similarity = 0.0
            for j in range(n):
                if i != j:
                    max_similarity = max(max_similarity, similarity_matrix[i][j])
            
            # å°‡ç›¸ä¼¼åº¦è½‰æ›ç‚º0-100åˆ†
            score = int(max_similarity * 100)
            scores[i] = score
        
        return scores


# ä¿æŒå‘å¾Œç›¸å®¹çš„å‡½æ•¸æ¥å£
def calculate_similarity_flags(texts: List[str], names: List[str] = None, hi: float = 0.85, mid: float = 0.70, min_length: int = 50, use_api: bool = True) -> Tuple[List[int], dict]:
    """
    è¨ˆç®—ç­”æ¡ˆé–“çš„ç›¸ä¼¼åº¦ï¼Œæª¢æ¸¬æ½›åœ¨æŠ„è¥² - å‘å¾Œç›¸å®¹å‡½æ•¸
    æ”¯æ´ GenAI (éœ€è¦API) å’ŒéGenAIæ–¹æ³• (æœ¬åœ°è¨ˆç®—)
    
    Args:
        texts: å­¸ç”Ÿç­”æ¡ˆåˆ—è¡¨
        names: å­¸ç”Ÿå§“ååˆ—è¡¨ï¼ˆå¯é¸ï¼‰
        hi: é«˜ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.85ï¼‰
        mid: ä¸­ç­‰ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.70ï¼‰
        min_length: æœ€å°æ–‡æœ¬é•·åº¦é–¾å€¼ï¼ˆé è¨­ 50 å­—ç¬¦ï¼‰
        use_api: æ˜¯å¦ä½¿ç”¨GenAI API (é è¨­ True)
    
    Returns:
        tuple: (similarity_flags, detailed_results)
               similarity_flags: list[int] - ç›¸ä¼¼åº¦æ¨™è¨˜ (0=ç„¡ç›¸ä¼¼, 1=ä¸­ç­‰ç›¸ä¼¼, 2=é«˜åº¦ç›¸ä¼¼, -1=éŒ¯èª¤)
               detailed_results: dict - è©³ç´°åˆ†æçµæœ
    """
    if not DO_SIMILARITY_CHECK or len(texts) < 2:
        return [0] * len(texts), {"status": "skipped", "method": "none"}
    
    # ä½¿ç”¨é…ç½®æª”æ¡ˆä¸­çš„é–¾å€¼
    thresholds = SIMILARITY_THRESHOLDS
    hi = thresholds.get('high', hi)
    mid = thresholds.get('medium', mid)
    min_length = thresholds.get('min_length', min_length)
    
    if use_api:
        # ä½¿ç”¨ GenAI API æ–¹æ³•
        try:
            # é è™•ç†æ–‡æœ¬
            processed_texts = []
            valid_indices = []
            
            for i, text in enumerate(texts):
                if text and text.strip() and len(text.strip()) >= min_length:
                    # ç°¡å–®çš„æ–‡æœ¬æ¸…ç†
                    cleaned_text = text.strip()
                    # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
                    cleaned_text = ' '.join(cleaned_text.split())
                    processed_texts.append(cleaned_text)
                    valid_indices.append(i)
                else:
                    processed_texts.append(" ")
                    valid_indices.append(i)
            
            # å¦‚æœæœ‰æ•ˆæ–‡æœ¬å°‘æ–¼ 2 å€‹ï¼Œè·³éç›¸ä¼¼åº¦æª¢æŸ¥
            valid_texts = [processed_texts[i] for i in range(len(processed_texts)) if len(processed_texts[i].strip()) >= min_length]
            if len(valid_texts) < 2:
                return [0] * len(texts), {"status": "insufficient_data", "method": "genai"}
            
            # è¨ˆç®—èªæ„åµŒå…¥
            result = genai.embed_content(
                model="models/text-embedding-004", 
                content=processed_texts, 
                task_type="RETRIEVAL_DOCUMENT"
            )
            embs = result['embedding']
            
            # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
            sims = cosine_similarity(embs)
            np.fill_diagonal(sims, 0)  # è¨­ç½®å°è§’ç·šç‚º 0ï¼Œé¿å…è‡ªå·±å’Œè‡ªå·±æ¯”è¼ƒ
            
            # åˆ†æç›¸ä¼¼åº¦çµæœ
            similarity_flags = []
            high_similarity_pairs = []
            
            for i in range(len(texts)):
                if len(processed_texts[i].strip()) < min_length:
                    # æ–‡æœ¬éçŸ­ï¼Œä¸åƒèˆ‡ç›¸ä¼¼åº¦æª¢æŸ¥
                    similarity_flags.append(0)
                    continue
                    
                max_sim = np.max(sims[i])
                max_sim_idx = np.argmax(sims[i])
                
                # ç¢ºå®šç›¸ä¼¼åº¦ç­‰ç´š
                if max_sim >= hi:
                    flag = 2
                    # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦é…å°
                    if names:
                        pair_info = f"{names[i]} â†” {names[max_sim_idx]} (ç›¸ä¼¼åº¦: {max_sim:.3f})"
                    else:
                        pair_info = f"å­¸ç”Ÿ {i+1} â†” å­¸ç”Ÿ {max_sim_idx+1} (ç›¸ä¼¼åº¦: {max_sim:.3f})"
                    high_similarity_pairs.append(pair_info)
                elif max_sim >= mid:
                    flag = 1
                else:
                    flag = 0
                    
                similarity_flags.append(flag)
            
            # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦é…å°åˆ°æ—¥èªŒ
            if high_similarity_pairs:
                logging.warning(f"æª¢æ¸¬åˆ° {len(high_similarity_pairs)} å°é«˜ç›¸ä¼¼åº¦ç­”æ¡ˆ:")
                for pair in high_similarity_pairs:
                    logging.warning(f"  ğŸš¨ {pair}")
            
            # æº–å‚™è©³ç´°çµæœ
            detailed_analysis = {
                "status": "completed",
                "method": "genai",
                "similarity_matrix": sims.tolist(),
                "high_similarity_pairs": high_similarity_pairs,
                "total_comparisons": len(texts) * (len(texts) - 1) // 2,
                "flagged_pairs": len(high_similarity_pairs)
            }
            
            return similarity_flags, detailed_analysis
            
        except Exception as e:
            logging.error(f"GenAI ç›¸ä¼¼åº¦è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # å¦‚æœGenAIå¤±æ•—ï¼Œfallbackåˆ°éGenAIæ–¹æ³•
            use_api = False
    
    if not use_api:
        # ä½¿ç”¨é GenAI æ–¹æ³•ï¼ˆå¾ alternative_similarity_methods.py å°å…¥ï¼‰
        try:
            from .alternative_similarity_methods import calculate_text_similarity_enhanced, calculate_tfidf_similarity
            
            # ä½¿ç”¨å¢å¼·ç‰ˆæœ¬åœ°æ–¹æ³•ï¼šå¤šç®—æ³•èåˆæª¢æ¸¬
            enhanced_results, enhanced_details = calculate_text_similarity_enhanced(texts, names, threshold=mid)
            
            # ä½¿ç”¨TF-IDFç›¸ä¼¼åº¦ä½œç‚ºè£œå……é©—è­‰
            tfidf_results, tfidf_details = calculate_tfidf_similarity(texts, threshold=mid)
            
            # ç¶œåˆå…©ç¨®æ–¹æ³•çš„çµæœï¼ˆä»¥å¢å¼·æ–¹æ³•ç‚ºä¸»ï¼‰
            combined_flags = []
            for i in range(len(texts)):
                enhanced_flag = enhanced_results[i] if i < len(enhanced_results) else 0
                tfidf_flag = tfidf_results[i] if i < len(tfidf_results) else 0
                
                # å–è¼ƒé«˜çš„ç›¸ä¼¼åº¦æ¨™è¨˜ï¼ˆä»¥å¢å¼·æ–¹æ³•ç‚ºä¸»ï¼‰
                combined_flag = max(enhanced_flag, tfidf_flag)
                combined_flags.append(combined_flag)
            
            # æº–å‚™è©³ç´°çµæœ
            detailed_analysis = {
                "status": "completed",
                "method": "enhanced_local",
                "enhanced_results": {
                    "flags": enhanced_results,
                    "details": enhanced_details
                },
                "tfidf_results": {
                    "flags": tfidf_results,
                    "details": tfidf_details
                },
                "combined_method": "max",
                "total_comparisons": len(texts) * (len(texts) - 1) // 2,
                "flagged_pairs": sum(1 for flag in combined_flags if flag >= 1)
            }
            
            return combined_flags, detailed_analysis
            
        except Exception as e:
            logging.error(f"æœ¬åœ°ç›¸ä¼¼åº¦è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return [-1] * len(texts), {"status": "error", "method": "local", "error": str(e)}
    
    return [-1] * len(texts), {"status": "error", "method": "unknown"}

def get_detailed_similarity_analysis(texts: List[str], names: List[str] = None, threshold: float = 0.70) -> dict:
    """
    å–å¾—è©³ç´°çš„ç›¸ä¼¼åº¦åˆ†æå ±å‘Š
    
    Args:
        texts: å­¸ç”Ÿç­”æ¡ˆåˆ—è¡¨
        names: å­¸ç”Ÿå§“ååˆ—è¡¨ï¼ˆå¯é¸ï¼‰
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
    
    Returns:
        dict: åŒ…å«ç›¸ä¼¼åº¦çŸ©é™£å’Œè©³ç´°åˆ†æçš„å­—å…¸
    """
    if not DO_SIMILARITY_CHECK or len(texts) < 2:
        return {"status": "skipped", "reason": "ç›¸ä¼¼åº¦æª¢æŸ¥å·²é—œé–‰æˆ–æ–‡æœ¬æ•¸é‡ä¸è¶³"}
    
    try:
        # é è™•ç†æ–‡æœ¬ï¼ˆèˆ‡ä¸Šé¢çš„å‡½æ•¸ä¿æŒä¸€è‡´ï¼‰
        safe_texts = [t.strip() if t and t.strip() else " " for t in texts]
        
        # è¨ˆç®—åµŒå…¥å‘é‡
        result = genai.embed_content(
            model="models/text-embedding-004", 
            content=safe_texts, 
            task_type="RETRIEVAL_DOCUMENT"
        )
        embs = result['embedding']
        
        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        sims = cosine_similarity(embs)
        np.fill_diagonal(sims, 0)
        
        # æ‰¾å‡ºé«˜ç›¸ä¼¼åº¦é…å°
        high_similarity_pairs = []
        for i in range(len(texts)):
            for j in range(i + 1, len(texts)):
                if sims[i][j] >= threshold:
                    student_i = names[i] if names else f"å­¸ç”Ÿ {i+1}"
                    student_j = names[j] if names else f"å­¸ç”Ÿ {j+1}"
                    high_similarity_pairs.append({
                        "student_1": student_i,
                        "student_2": student_j,
                        "similarity": float(sims[i][j]),
                        "index_1": i,
                        "index_2": j
                    })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        high_similarity_pairs.sort(key=lambda x: x["similarity"], reverse=True)
        
        return {
            "status": "completed",
            "similarity_matrix": sims.tolist(),
            "high_similarity_pairs": high_similarity_pairs,
            "total_comparisons": len(texts) * (len(texts) - 1) // 2,
            "flagged_pairs": len(high_similarity_pairs)
        }
        
    except Exception as e:
        logging.error(f"è©³ç´°ç›¸ä¼¼åº¦åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {"status": "error", "error": str(e)}
