# analyzer.py
# æ ¸å¿ƒåˆ†æé‚è¼¯æ¨¡çµ„ - é‡æ§‹ç‰ˆæœ¬

import os, re, json, asyncio, logging
import pandas as pd 
import numpy as np
from typing import Dict, List, Tuple, Optional, Any

# å¼•å…¥æœ¬åœ°æ¨¡çµ„
from .config import TARGET_SCORE_Q, BATCH_SIZE, DO_SIMILARITY_CHECK, RUBRICS
from .gemini_client import GeminiClient
from .data_processor import DataProcessor
from .visualization import VisualizationEngine
from .similarity_detector import SimilarityDetector

# --- è©•åˆ†æ¨™æº– (Rubrics) ---
RUBRICS = {
1: '''Rubric (10 pts total)

Section A â€“ CZ vs FZ singleâ€‘crystal Si comparison (0â€‘4 pts)
  â€¢ Clearly list â‰¥â€¯2 advantages and â‰¥â€¯2 disadvantages for **each** process  
    â€“ e.g. CZ: large diameter, cheaper / higher O contamination, lower resistivity  
    â€“ FZ: crucibleâ€‘less, ultraâ€‘high purity, high resistivity / smaller boule, costly  
  â€¢ 0.5â€¯pt per correct advantage/disadvantage, up to 4â€¯pts

Section B â€“ Channeling effect definition & impact (0â€‘3 pts)
  â€¢ Defines channeling as ions travelling along lowâ€‘index crystal axes/planes (1â€¯pt)  
  â€¢ Describes deeper projected range / dose loss / tail in dopant profile (1â€¯pt)  
  â€¢ Mentions dependence on crystal orientation/energy (1â€¯pt)

Section C â€“ Mitigation methods (0â€‘3 pts)
  Any three of the following, 1â€¯pt each (max 3â€¯pts):  
    â€“ Tilt/rotate wafer during implantation  
    â€“ Use amorphizing preâ€‘implant (e.g. Si, Ge)  
    â€“ Grow/retain surface oxide or SiN mask  
    â€“ Implant through amorphous layer (screen oxide)  
    â€“ Use random beam incidence or beam wobbling
''',
    2: '''Rubric (10 pts total) â€” Student **answers any TWO** subâ€‘problems  
Score each answered subâ€‘problem 0â€‘5 pts, keep the best two (max 10)

Subâ€‘problem 1  Massâ€‘transportâ€‘ vs. surfaceâ€‘reactionâ€‘limited CVD (0â€‘5)
  â€¢ Correct definition of each regime & rateâ€‘determining step (2â€¯pts)  
  â€¢ Describes dependence on temperature, pressure, boundary layer (1â€¯pt)  
  â€¢ Mentions impact on thickness uniformity or step coverage (1â€¯pt)  
  â€¢ Gives practical example or sketch of concentration profile (1â€¯pt)

Subâ€‘problem 2  MBE working principle (0â€‘5)
  â€¢ UHV environment & effusion cells produce atom/molecule beams (2â€¯pts)  
  â€¢ Ballistic arrival / adsorptionâ€“surface diffusionâ€“incorporation process (1â€¯pt)  
  â€¢ Inâ€‘situ monitoring (e.g. RHEED) & precise flux control (1â€¯pt)  
  â€¢ Typical growth rate (~1â€¯Âµmâ€¯hâ»Â¹) & ultraâ€‘high purity advantage (1â€¯pt)

Subâ€‘problem 3  Exceeding critical thickness in heteroepitaxy (0â€‘5)
  â€¢ Introduces misfit strain & Matthewsâ€“Blakeslee criterion (1â€¯pt)  
  â€¢ Formation of misfit dislocations / strain relaxation (2â€¯pts)  
  â€¢ Possible 3â€‘D islanding (Sâ€“K), surface roughening or cracks (1â€¯pt)  
  â€¢ Electrical/optical degradation consequence (1â€¯pt)
''',
    3: '''Rubric (10 pts total) â€” Student **answers any TWO** subâ€‘problems  
Score each answered subâ€‘problem 0â€‘5 pts, keep the best two (max 10)

Subâ€‘problem 1  Si vs GaAs band structure differences (0â€‘5)
  â€¢ Indirect (Si) vs direct (GaAs) bandgap nature & values (2â€¯pts)  
  â€¢ Conductionâ€‘band valley positions / densityâ€‘ofâ€‘states (1â€¯pt)  
  â€¢ Carrier mobility & effective mass comparison (1â€¯pt)  
  â€¢ Consequence for optoelectronic efficiency (1â€¯pt)

Subâ€‘problem 2  â€œStraddling gapâ€ heterojunction (Typeâ€‘I) (0â€‘5)
  â€¢ Correctly picks Typeâ€‘I (1â€¯pt)  
  â€¢ Conduction & valence bands of widerâ€‘gap material both higher/lower enclosing narrowâ€‘gap (2â€¯pts)  
  â€¢ Draws / verbally describes band diagram & carrier confinement (2â€¯pts)

Subâ€‘problem 3  Multijunction solarâ€‘cell spectral utilization (0â€‘5)
  â€¢ Bandgap stacking / current matching concept (2â€¯pts)  
  â€¢ Use of tunnel junctions / graded buffers (1â€¯pt)  
  â€¢ Spectrum splitting or latticeâ€‘matched material selection (1â€¯pt)  
  â€¢ Antiâ€‘reflection or lightâ€‘management strategy (1â€¯pt)
''',
    4: '''Rubric (10 pts total) â€” Student **answers any TWO** subâ€‘problems  
Score each answered subâ€‘problem 0â€‘5 pts, keep the best two (max 10)

Subâ€‘problem 1  Early challenges in GaN on sapphire (0â€‘5)
  â€¢ ~16â€¯% lattice mismatch & thermalâ€‘expansion mismatch (2â€¯pts)  
  â€¢ High threading dislocation density / cracking (1â€¯pt)  
  â€¢ Poor surface wetting, nucleation issues prior to LTâ€‘buffer invention (1â€¯pt)  
  â€¢ Impact on LED efficiency / reliability (1â€¯pt)

Subâ€‘problem 2  Difficulty of achieving pâ€‘type GaN (0â€‘5)
  â€¢ Deep acceptor level of Mg (â‰ˆ200â€¯meV) limits hole activation (2â€¯pts)  
  â€¢ H passivation forming Mgâ€“H complexes, need anneal (1â€¯pt)  
  â€¢ Compensation by native donors / defects (1â€¯pt)  
  â€¢ Historically low hole mobility / conductivity (1â€¯pt)

Subâ€‘problem 3  (D) Lower manufacturing cost? â€” critical discussion (0â€‘5)
  â€¢ States that early GaN/Sapphire actually â†‘ cost due to low yield (1â€¯pt)  
  â€¢ Explains how subsequent massâ€‘production & cheap sapphire made cost reasonable (1â€¯pt)  
  â€¢ Compares to SiC, bulk GaN or phosphorâ€‘converted alternatives (1â€¯pt)  
  â€¢ Evaluates epi reactor throughput, wafer price, device efficiency vs cost (2â€¯pts)
''',
    11: '''Rubric (10 pts total)

Partâ€¯1  Quantum confinement in 0â€‘D nanomaterials (0â€‘5)
  â€¢ Defines confinement when particle size â‰² exciton Bohr radius (1â€¯pt)  
  â€¢ Energy levels become discrete, bandgap widens with decreasing size (2â€¯pts)  
  â€¢ Mentions sizeâ€‘tunable optical emission / quantumâ€‘size effect (1â€¯pt)  
  â€¢ Gives formula E âˆ 1/LÂ² or cites typical CdSe Qâ€‘dot example (1â€¯pt)

Partâ€¯2  Si nanowires as Liâ€‘ion anode (0â€‘5)
  â€¢ Lists Si theoretical capacity â‰ˆ4200â€¯mAhâ€¯gâ»Â¹ (1â€¯pt)  
  â€¢ bulk Si issues: >300â€¯% volume expansion, pulverization, loss of contact (2â€¯pts)  
  â€¢ SiNWs accommodate strain radially / maintain electrical pathway (1â€¯pt)  
  â€¢ Large surface area for fast Li diffusion & facile SEI formation control (1â€¯pt)
''',
}

# --- Prompt æ¨¡æ¿ ---
PROMPT_TEMPLATE = """You are a meticulous graduate-level TA.
First, judge whether the following answer exhibits obvious LLM writing style (including but not limited to overly smooth transitions, template phrases like 'moreover', almost no typos).
Return an integer 'ai_risk' from 0â€‘100 (higher = more AI-like).
{grade_block}
Respond ONLY with a valid JSON object like {{"ai_risk": ..., "score": ...}}.

Question:
{question}

Answer:
{answer}
"""

def log_to_frontend(message, callback):
    """å®‰å…¨åœ°å‘¼å«å‰ç«¯æ—¥èªŒå›å‘¼å‡½å¼"""
    if callback:
        callback(message)
    else:
        print(message)

def load_exam(csv_path, log_callback):
    """å¾ CSV æª”æ¡ˆè¼‰å…¥è€ƒå·ç­”æ¡ˆ"""
    try:
        df = pd.read_csv(
            csv_path,
            encoding='utf-8',
            dtype=str,
            quotechar='"',
            escapechar='\\'
        )
        # å»é™¤æ¬„ä½åç¨±å‰å¾Œç©ºç™½ï¼Œä¸¦å°‡æ›è¡Œè½‰ç‚ºç©ºæ ¼
        df.columns = (
            df.columns
            .str.strip()
            .str.replace('\n', ' ', regex=False)
        )
        
        log_to_frontend(f"ğŸ“Š åŸå§‹æª”æ¡ˆè¼‰å…¥: {len(df)} è¡Œ", log_callback)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ 'name' æ¬„ä½
        if 'name' not in df.columns:
            log_to_frontend("âŒ æ‰¾ä¸åˆ° 'name' æ¬„ä½ï¼Œè«‹æª¢æŸ¥CSVæ ¼å¼", log_callback)
            return None, None
            
        # å»é™¤é‡è¤‡çš„å­¸ç”Ÿè¨˜éŒ„ï¼Œå„ªå…ˆä¿ç•™æœ€é«˜åˆ†æ•¸çš„è¨˜éŒ„
        original_count = len(df)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ score æ¬„ä½ä¾†åˆ¤æ–·æœ€é«˜åˆ†
        if 'score' in df.columns:
            # å°‡åˆ†æ•¸è½‰æ›ç‚ºæ•¸å€¼å‹æ…‹
            df['score_numeric'] = pd.to_numeric(df['score'], errors='coerce').fillna(0)
            # æ ¹æ“šå§“ååˆ†çµ„ï¼Œä¿ç•™æ¯çµ„ä¸­åˆ†æ•¸æœ€é«˜çš„è¨˜éŒ„
            df = df.loc[df.groupby('name')['score_numeric'].idxmax()]
            df = df.drop(columns=['score_numeric'])  # ç§»é™¤è‡¨æ™‚æ¬„ä½
            log_to_frontend("ğŸ“Š ä¿ç•™ç­–ç•¥: æ¯ä½å­¸ç”Ÿä¿ç•™æœ€é«˜åˆ†æ•¸çš„è¨˜éŒ„", log_callback)
        else:
            # å¦‚æœæ²’æœ‰åˆ†æ•¸æ¬„ä½ï¼Œå‰‡ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç¾çš„è¨˜éŒ„
            df = df.drop_duplicates(subset=['name'], keep='first')
            log_to_frontend("ğŸ“Š ä¿ç•™ç­–ç•¥: æ¯ä½å­¸ç”Ÿä¿ç•™ç¬¬ä¸€æ¬¡è¨˜éŒ„", log_callback)
        
        deduplicated_count = len(df)
        
        if original_count != deduplicated_count:
            removed_count = original_count - deduplicated_count
            log_to_frontend(f"ğŸ”„ å»é™¤é‡è¤‡è¨˜éŒ„: {removed_count} å€‹é‡è¤‡ä½œç­”ï¼Œä¿ç•™ {deduplicated_count} ä½å­¸ç”Ÿ", log_callback)
        
        # å»é™¤å§“åç‚ºç©ºçš„è¡Œ
        df = df.dropna(subset=['name'])
        df = df[df['name'].str.strip() != '']
        final_count = len(df)
        
        if deduplicated_count != final_count:
            log_to_frontend(f"ğŸ§¹ å·²ç§»é™¤ç©ºç™½å§“å: {deduplicated_count} -> {final_count} è¡Œ", log_callback)
            
    except FileNotFoundError:
        log_to_frontend(f"âŒ æ‰¾ä¸åˆ°æŒ‡å®šçš„æª”æ¡ˆ: {csv_path}", log_callback)
        return None, None
    except Exception as e:
        log_to_frontend(f"âŒ è®€å–CSVæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", log_callback)
        return None, None
    
    # æ‰¾åˆ°çµæ§‹æ¨™è¨˜æ¬„ä½çš„ç´¢å¼•
    try:
        attempt_idx = df.columns.get_loc('attempt')
        n_correct_idx = df.columns.get_loc('n correct')
    except KeyError as e:
        log_to_frontend(f"âŒ æ‰¾ä¸åˆ°å¿…è¦çš„æ¬„ä½: {e}ï¼Œè«‹æª¢æŸ¥CSVæ ¼å¼", log_callback)
        return None, None
    
    # è§£æattemptå’Œn correctä¹‹é–“çš„é¡Œç›®/åˆ†æ•¸é…å°
    q_map = {}
    q_counter = 1
    
    for i in range(attempt_idx + 1, n_correct_idx, 2):
        if i + 1 < n_correct_idx:  # ç¢ºä¿æœ‰é…å°çš„åˆ†æ•¸æ¬„ä½
            question_col = df.columns[i]
            score_col = df.columns[i + 1]
            
            # æª¢æŸ¥åˆ†æ•¸æ¬„ä½æ˜¯å¦ç‚ºæ•¸å€¼å‹æ…‹æˆ–åŒ…å«åˆ†æ•¸è³‡è¨Š
            if (pd.to_numeric(df[score_col], errors='coerce').notna().any() or 
                any(str(val).replace('.', '').isdigit() for val in df[score_col].dropna())):
                q_map[q_counter] = question_col
                q_counter += 1
                log_to_frontend(f"  æ‰¾åˆ°é¡Œç›® {q_counter-1}: {question_col[:50]}...", log_callback)
    
    log_to_frontend(f"âœ… æˆåŠŸè¼‰å…¥ {os.path.basename(csv_path)}ï¼Œæ‰¾åˆ° {len(df)} ä½å­¸ç”Ÿèˆ‡ {len(q_map)} é¡Œå•ç­”ã€‚", log_callback)
    return df, q_map

def calculate_similarity_flags(texts: list[str], names: list[str] = None, hi=0.85, mid=0.70, min_length=50, use_api=True) -> tuple:
    """
    è¨ˆç®—ç­”æ¡ˆé–“çš„ç›¸ä¼¼åº¦ï¼Œæª¢æ¸¬æ½›åœ¨æŠ„è¥²
    æ”¯æ´ GenAI (éœ€è¦API) å’ŒéGenAIæ–¹æ³• (æœ¬åœ°è¨ˆç®—)
    èª’
    Args:
        texts: å­¸ç”Ÿç­”æ¡ˆåˆ—è¡¨
        names: å­¸ç”Ÿå§“ååˆ—è¡¨ï¼ˆå¯é¸ï¼‰
        hi: é«˜ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.85ï¼‰
        mid: ä¸­ç­‰ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.70ï¼‰
        min_length: æœ€å°æ–‡æœ¬é•·åº¦é–¾å€¼ï¼ˆé è¨­ 50 å­—ç¬¦ï¼‰
        use_api: æ˜¯å¦ä½¿ç”¨GenAI API (é è¨­ True)
    
    Returns:
        tuple: (similarity_flags, detailed_results)
               similarity_flags: list[int] - ç›¸ä¼¼åº¦æ¨™è¨˜ (0=ç„¡ç›¸ä¼¼, 1=ä¸­ç­‰ç›¸ä¼¼, 2=é«˜åº¦ç›¸ä¼¼, -1=éŒ¯èª¤)
               detailed_results: dict - è©³ç´°åˆ†æçµæœ
    """
    if not DO_SIMILARITY_CHECK or len(texts) < 2:
        return [0] * len(texts), {"status": "skipped", "method": "none"}
    
    
    if use_api and gmodel:
        # ä½¿ç”¨ GenAI API æ–¹æ³•
        try:
            # é è™•ç†æ–‡æœ¬
            processed_texts = []
            valid_indices = []
            
            for i, text in enumerate(texts):
                if text and text.strip() and len(text.strip()) >= min_length:
                    # ç°¡å–®çš„æ–‡æœ¬æ¸…ç†
                    cleaned_text = text.strip()
                    # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
                    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
                    processed_texts.append(cleaned_text)
                    valid_indices.append(i)
                else:
                    processed_texts.append(" ")
                    valid_indices.append(i)
            
            # å¦‚æœæœ‰æ•ˆæ–‡æœ¬å°‘æ–¼ 2 å€‹ï¼Œè·³éç›¸ä¼¼åº¦æª¢æŸ¥
            valid_texts = [processed_texts[i] for i in range(len(processed_texts)) if len(processed_texts[i].strip()) >= min_length]
            if len(valid_texts) < 2:
                return [0] * len(texts), {"status": "insufficient_data", "method": "genai"}
            
            # è¨ˆç®—èªæ„åµŒå…¥
            result = genai.embed_content(
                model="models/text-embedding-004", 
                content=processed_texts, 
                task_type="RETRIEVAL_DOCUMENT"
            )
            embs = result['embedding']
            
            # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
            sims = cosine_similarity(embs)
            np.fill_diagonal(sims, 0)  # è¨­ç½®å°è§’ç·šç‚º 0ï¼Œé¿å…è‡ªå·±å’Œè‡ªå·±æ¯”è¼ƒ
            
            # åˆ†æç›¸ä¼¼åº¦çµæœ
            similarity_flags = []
            high_similarity_pairs = []
            
            for i in range(len(texts)):
                if len(processed_texts[i].strip()) < min_length:
                    # æ–‡æœ¬éçŸ­ï¼Œä¸åƒèˆ‡ç›¸ä¼¼åº¦æª¢æŸ¥
                    similarity_flags.append(0)
                    continue
                    
                max_sim = np.max(sims[i])
                max_sim_idx = np.argmax(sims[i])
                
                # ç¢ºå®šç›¸ä¼¼åº¦ç­‰ç´š
                if max_sim >= hi:
                    flag = 2
                    # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦é…å°
                    if names:
                        pair_info = f"{names[i]} â†” {names[max_sim_idx]} (ç›¸ä¼¼åº¦: {max_sim:.3f})"
                    else:
                        pair_info = f"å­¸ç”Ÿ {i+1} â†” å­¸ç”Ÿ {max_sim_idx+1} (ç›¸ä¼¼åº¦: {max_sim:.3f})"
                    high_similarity_pairs.append(pair_info)
                elif max_sim >= mid:
                    flag = 1
                else:
                    flag = 0
                    
                similarity_flags.append(flag)
            
            # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦é…å°åˆ°æ—¥èªŒ
            if high_similarity_pairs:
                logging.warning(f"æª¢æ¸¬åˆ° {len(high_similarity_pairs)} å°é«˜ç›¸ä¼¼åº¦ç­”æ¡ˆ:")
                for pair in high_similarity_pairs:
                    logging.warning(f"  ğŸš¨ {pair}")
            
            # æº–å‚™è©³ç´°çµæœ
            detailed_analysis = {
                "status": "completed",
                "method": "genai",
                "similarity_matrix": sims.tolist(),
                "high_similarity_pairs": high_similarity_pairs,
                "total_comparisons": len(texts) * (len(texts) - 1) // 2,
                "flagged_pairs": len(high_similarity_pairs)
            }
            
            return similarity_flags, detailed_analysis
            
        except Exception as e:
            logging.error(f"GenAI ç›¸ä¼¼åº¦è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # å¦‚æœGenAIå¤±æ•—ï¼Œfallbackåˆ°éGenAIæ–¹æ³•
            use_api = False
    
    if not use_api:
        # ä½¿ç”¨é GenAI æ–¹æ³•ï¼ˆå¾ alternative_similarity_methods.py å°å…¥ï¼‰
        try:
            from alternative_similarity_methods import calculate_text_similarity_enhanced, calculate_tfidf_similarity
            
            # ä½¿ç”¨å¢å¼·ç‰ˆæœ¬åœ°æ–¹æ³•ï¼šå¤šç®—æ³•èåˆæª¢æ¸¬
            enhanced_results, enhanced_details = calculate_text_similarity_enhanced(texts, names, threshold=mid)
            
            # ä½¿ç”¨TF-IDFç›¸ä¼¼åº¦ä½œç‚ºè£œå……é©—è­‰
            tfidf_results, tfidf_details = calculate_tfidf_similarity(texts, threshold=mid)
            
            # ç¶œåˆå…©ç¨®æ–¹æ³•çš„çµæœï¼ˆä»¥å¢å¼·æ–¹æ³•ç‚ºä¸»ï¼‰
            combined_flags = []
            for i in range(len(texts)):
                enhanced_flag = enhanced_results[i] if i < len(enhanced_results) else 0
                tfidf_flag = tfidf_results[i] if i < len(tfidf_results) else 0
                
                # å–è¼ƒé«˜çš„ç›¸ä¼¼åº¦æ¨™è¨˜ï¼ˆä»¥å¢å¼·æ–¹æ³•ç‚ºä¸»ï¼‰
                combined_flag = max(enhanced_flag, tfidf_flag)
                combined_flags.append(combined_flag)
            
            # æº–å‚™è©³ç´°çµæœ
            detailed_analysis = {
                "status": "completed",
                "method": "enhanced_local",
                "enhanced_results": {
                    "flags": enhanced_results,
                    "details": enhanced_details
                },
                "tfidf_results": {
                    "flags": tfidf_results,
                    "details": tfidf_details
                },
                "combined_method": "max",
                "total_comparisons": len(texts) * (len(texts) - 1) // 2,
                "flagged_pairs": sum(1 for flag in combined_flags if flag >= 1)
            }
            
            return combined_flags, detailed_analysis
            
        except Exception as e:
            logging.error(f"æœ¬åœ°ç›¸ä¼¼åº¦è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return [-1] * len(texts), {"status": "error", "method": "local", "error": str(e)}
    
    return [-1] * len(texts), {"status": "error", "method": "unknown"}

def get_detailed_similarity_analysis(texts: list[str], names: list[str] = None, threshold=0.70):
    """
    å–å¾—è©³ç´°çš„ç›¸ä¼¼åº¦åˆ†æå ±å‘Š
    
    Args:
        texts: å­¸ç”Ÿç­”æ¡ˆåˆ—è¡¨
        names: å­¸ç”Ÿå§“ååˆ—è¡¨ï¼ˆå¯é¸ï¼‰
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
    
    Returns:
        dict: åŒ…å«ç›¸ä¼¼åº¦çŸ©é™£å’Œè©³ç´°åˆ†æçš„å­—å…¸
    """
    if not DO_SIMILARITY_CHECK or len(texts) < 2:
        return {"status": "skipped", "reason": "ç›¸ä¼¼åº¦æª¢æŸ¥å·²é—œé–‰æˆ–æ–‡æœ¬æ•¸é‡ä¸è¶³"}
    
    try:
        # é è™•ç†æ–‡æœ¬ï¼ˆèˆ‡ä¸Šé¢çš„å‡½æ•¸ä¿æŒä¸€è‡´ï¼‰
        safe_texts = [t.strip() if t and t.strip() else " " for t in texts]
        
        # è¨ˆç®—åµŒå…¥å‘é‡
        result = genai.embed_content(
            model="models/text-embedding-004", 
            content=safe_texts, 
            task_type="RETRIEVAL_DOCUMENT"
        )
        embs = result['embedding']
        
        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        sims = cosine_similarity(embs)
        np.fill_diagonal(sims, 0)
        
        # æ‰¾å‡ºé«˜ç›¸ä¼¼åº¦é…å°
        high_similarity_pairs = []
        for i in range(len(texts)):
            for j in range(i + 1, len(texts)):
                if sims[i][j] >= threshold:
                    student_i = names[i] if names else f"å­¸ç”Ÿ {i+1}"
                    student_j = names[j] if names else f"å­¸ç”Ÿ {j+1}"
                    high_similarity_pairs.append({
                        "student_1": student_i,
                        "student_2": student_j,
                        "similarity": float(sims[i][j]),
                        "index_1": i,
                        "index_2": j
                    })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        high_similarity_pairs.sort(key=lambda x: x["similarity"], reverse=True)
        
        return {
            "status": "completed",
            "similarity_matrix": sims.tolist(),
            "high_similarity_pairs": high_similarity_pairs,
            "total_comparisons": len(texts) * (len(texts) - 1) // 2,
            "flagged_pairs": len(high_similarity_pairs)
        }
        
    except Exception as e:
        logging.error(f"è©³ç´°ç›¸ä¼¼åº¦åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {"status": "error", "error": str(e)}

async def gemini_eval(question: str, rubric: str, answer: str, need_score: bool) -> tuple:
    """éåŒæ­¥å‘¼å« Gemini API é€²è¡Œ AI é¢¨æ ¼åˆ†æèˆ‡è©•åˆ†"""
    if not answer or not answer.strip():
        return (0, 0 if need_score else None)
    
    if need_score:
        grade_block = f"""Then grade the answer based on this rubric (return an integer score 0-10):

{rubric}

Grade the answer objectively according to the rubric criteria."""
    else:
        grade_block = "Grading is not required for this question."
    
    prompt = PROMPT_TEMPLATE.format(question=question, answer=answer, grade_block=grade_block)
    try:
        resp = await gmodel.generate_content_async(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.0, response_mime_type="application/json"),
            request_options={"timeout": 120}
        )
        if not resp.text: return (None, None)
        js = json.loads(resp.text)
        return (js.get("ai_risk"), js.get("score"))
    except Exception as e:
        logging.error(f"Gemini API å‘¼å«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return (None, None)

async def process_question(df, qid, col, log_callback, use_genai=True):
    """è™•ç†å–®ä¸€å•é¡Œçš„æ‰€æœ‰å­¸ç”Ÿç­”æ¡ˆ"""
    log_to_frontend(f"â¡ï¸ é–‹å§‹è™•ç† Q{qid}...", log_callback)
    q_text = col.split(":", 1)[1].strip()
    need_score = qid in TARGET_SCORE_Q
    rubric = RUBRICS.get(qid, "")
    
    sub = df[["name", col]].rename(columns={col: "answer"}).fillna("")
    
    # ç›¸ä¼¼åº¦æª¢æŸ¥ï¼ˆåŒæ™‚ä½¿ç”¨GenAIå’ŒéGenAIæ–¹æ³•ï¼Œæ ¹æ“šuse_genaiæ±ºå®šï¼‰
    sim_flags, sim_details = calculate_similarity_flags(
        sub["answer"].tolist(), 
        names=sub["name"].tolist(),
        use_api=use_genai
    )
    sub[f"Q{qid}_sim_flag"] = sim_flags
    
    if use_genai:
        # ä½¿ç”¨GenAIé€²è¡ŒAIé¢¨éšªåˆ†æå’Œè©•åˆ†
        out_ai, out_sc = [], []
        chunks = [sub.iloc[i:i + BATCH_SIZE] for i in range(0, len(sub), BATCH_SIZE)]
        
        for i, chunk in enumerate(chunks):
            log_to_frontend(f"    Q{qid}: è™•ç†æ‰¹æ¬¡ {i+1}/{len(chunks)}", log_callback)
            tasks = [gemini_eval(q_text, rubric, a, need_score) for a in chunk["answer"]]
            results = await asyncio.gather(*tasks)
            out_ai.extend([r[0] for r in results])
            out_sc.extend([r[1] for r in results])
            
        sub[f"Q{qid}_ai_risk"] = out_ai
        if need_score:
            sub[f"Q{qid}_score"] = out_sc
    else:
        # ä¸ä½¿ç”¨GenAIï¼Œè¨­ç½®é è¨­å€¼
        sub[f"Q{qid}_ai_risk"] = [0] * len(sub)  # ä¸é€²è¡ŒAIé¢¨éšªåˆ†æ
        if need_score:
            sub[f"Q{qid}_score"] = [None] * len(sub)  # ä¸é€²è¡Œè©•åˆ†
        log_to_frontend(f"    Q{qid}: è·³éAIåˆ†æå’Œè©•åˆ†ï¼ˆç„¡APIé‡‘é‘°ï¼‰", log_callback)
    
    # å‰µå»ºç›¸ä¼¼åº¦çŸ©é™£è¦–è¦ºåŒ–
    log_to_frontend(f"    Q{qid}: å‰µå»ºç›¸ä¼¼åº¦åˆ†æè¦–è¦ºåŒ–...", log_callback)
    genai_matrix, local_matrix = create_similarity_matrix_visualization(
        sub["answer"].tolist(), 
        sub["name"].tolist(), 
        str(qid)
    )
    
    # å°‡è¦–è¦ºåŒ–çµæœæ·»åŠ åˆ°çµæœä¸­
    if genai_matrix:
        sub[f"Q{qid}_genai_matrix"] = [genai_matrix] * len(sub)
    if local_matrix:
        sub[f"Q{qid}_local_matrix"] = [local_matrix] * len(sub)
        
    return sub.drop(columns=["answer"])

async def run_analysis(api_key: str, csv_path: str, out_base_path: str, log_callback, model_name: str = "gemini-1.5-pro-latest"):
    """åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹çš„ä¸»å‡½å¼"""
    # APIé‡‘é‘°ç¾åœ¨ç‚ºå¯é¸åƒæ•¸
    use_genai = bool(api_key and api_key.strip())
    
    if use_genai:
        if not configure_gemini(api_key, model_name):
            log_to_frontend("âŒ API é‡‘é‘°è¨­å®šå¤±æ•—ï¼Œè«‹æª¢æŸ¥é‡‘é‘°æ˜¯å¦æ­£ç¢ºã€‚", log_callback)
            return
        log_to_frontend(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}", log_callback)
        log_to_frontend("ğŸ”— å°‡åŒæ™‚ä½¿ç”¨GenAIå’ŒéGenAIæ–¹æ³•é€²è¡Œåˆ†æ", log_callback)
    else:
        log_to_frontend("ğŸ“Š åªä½¿ç”¨éGenAIæ–¹æ³•é€²è¡Œåˆ†æ", log_callback)

    df, qmap = load_exam(csv_path, log_callback)
    if df is None: return

    merged_df = df[["name"]].copy()
    
    for qid, col in qmap.items():
        res_df = await process_question(df, qid, col, log_callback, use_genai)
        merged_df = merged_df.merge(res_df, on="name", how="left")
        
    # å®šç¾©å„ç¨®æ ¼å¼çš„è¼¸å‡ºè·¯å¾‘
    xlsx_path = f"{out_base_path}.xlsx"
    csv_path_out = f"{out_base_path}.csv"
    yaml_path = f"{out_base_path}.yaml"
    html_path = f"{out_base_path}.html"

    try:
        # å„²å­˜ç‚º Excel
        merged_df.to_excel(xlsx_path, index=False, engine='openpyxl')
        log_to_frontend(f"ğŸ‰ Excel å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{xlsx_path}", log_callback)

        # å„²å­˜ç‚º CSV
        merged_df.to_csv(csv_path_out, index=False)
        log_to_frontend(f"ğŸ‰ CSV å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{csv_path_out}", log_callback)

        # å„²å­˜ç‚º YAML
        # å°‡ DataFrame è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨ä»¥ä¾¿ YAML åºåˆ—åŒ–
        yaml_data = merged_df.to_dict(orient='records')
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)
        log_to_frontend(f"ğŸ‰ YAML å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{yaml_path}", log_callback)

        # å„²å­˜ç‚º HTMLï¼ˆåŒ…å«è¦–è¦ºåŒ–çŸ©é™£ï¼‰
        html_content = generate_enhanced_html_report(merged_df)
        
        html_output = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>AIåŠ©æ•™åˆ†æå ±å‘Š</title>
            <style>
                body {{ 
                    font-family: 'Segoe UI', Arial, sans-serif; 
                    margin: 20px; 
                    background-color: #f5f5f5;
                }}
                .container {{
                    max-width: 1200px;
                    margin: 0 auto;
                    background: white;
                    padding: 30px;
                    border-radius: 10px;
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }}
                h1 {{
                    color: #2c3e50;
                    text-align: center;
                    margin-bottom: 30px;
                    border-bottom: 3px solid #3498db;
                    padding-bottom: 15px;
                }}
                h2 {{
                    color: #34495e;
                    margin-top: 40px;
                    margin-bottom: 20px;
                    border-left: 4px solid #3498db;
                    padding-left: 15px;
                }}
                .table {{ 
                    width: 100%; 
                    border-collapse: collapse; 
                    margin: 20px 0;
                    box-shadow: 0 1px 3px rgba(0,0,0,0.2);
                }}
                .table th, .table td {{ 
                    border: 1px solid #ddd; 
                    padding: 12px; 
                    text-align: left; 
                }}
                .table th {{ 
                    background-color: #3498db; 
                    color: white;
                    font-weight: bold;
                }}
                .table-striped tbody tr:nth-of-type(odd) {{ 
                    background-color: #f9f9f9; 
                }}
                .similarity-matrix {{
                    text-align: center;
                    margin: 30px 0;
                    padding: 20px;
                    background: #f8f9fa;
                    border-radius: 8px;
                }}
                .matrix-image {{
                    max-width: 100%;
                    height: auto;
                    border: 1px solid #ddd;
                    border-radius: 5px;
                    margin: 10px;
                }}
                .matrix-container {{
                    display: flex;
                    flex-wrap: wrap;
                    justify-content: center;
                    gap: 20px;
                }}
                .matrix-item {{
                    flex: 1;
                    min-width: 300px;
                    max-width: 500px;
                }}
                .summary-stats {{
                    background: #e8f5e8;
                    border: 1px solid #27ae60;
                    border-radius: 5px;
                    padding: 15px;
                    margin: 20px 0;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>ğŸ“ AIåŠ©æ•™è€ƒå·åˆ†æå ±å‘Š</h1>
                {html_content}
            </div>
        </body>
        </html>
        """
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_output)
        log_to_frontend(f"ğŸ‰ HTML å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{html_path}", log_callback)

    except Exception as e:
        log_to_frontend(f"âŒ å„²å­˜å ±å‘Šå¤±æ•—: {e}", log_callback)

def generate_enhanced_html_report(merged_df):
    """
    ç”ŸæˆåŒ…å«è¦–è¦ºåŒ–çŸ©é™£çš„å¢å¼·HTMLå ±å‘Š
    """
    html_parts = []
    
    # ç”Ÿæˆçµ±è¨ˆæ‘˜è¦
    total_students = len(merged_df)
    questions = [col for col in merged_df.columns if col.startswith('Q') and '_sim_flag' in col]
    html_parts.append(f"""
    <div class="summary-stats">
        <h2>ğŸ“Š åˆ†ææ‘˜è¦</h2>
        <p><strong>ç¸½å­¸ç”Ÿæ•¸:</strong> {total_students}</p>
        <p><strong>åˆ†æé¡Œç›®æ•¸:</strong> {len(questions)}</p>
        <p><strong>ç›¸ä¼¼åº¦æª¢æ¸¬:</strong> {'å·²å•Ÿç”¨' if questions else 'æœªå•Ÿç”¨'}</p>
    </div>
    """)
    
    # ç‚ºæ¯å€‹é¡Œç›®å‰µå»ºç« ç¯€
    current_qid = None
    for col in merged_df.columns:
        if '_sim_flag' in col:
            qid = col.split('_')[0][1:]  # æå–Qå¾Œçš„æ•¸å­—
            if qid != current_qid:
                current_qid = qid
                html_parts.append(f"<h2>ğŸ“ é¡Œç›® {qid} - ç›¸ä¼¼åº¦åˆ†æ</h2>")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰é«˜ç›¸ä¼¼åº¦æ¡ˆä¾‹
                sim_flags = merged_df[f'Q{qid}_sim_flag'].tolist()
                high_sim_count = sum(1 for flag in sim_flags if flag == 2)
                medium_sim_count = sum(1 for flag in sim_flags if flag == 1)
                
                html_parts.append(f"""
                <div class="summary-stats">
                    <p><strong>é«˜åº¦ç›¸ä¼¼:</strong> {high_sim_count} ä½å­¸ç”Ÿ</p>
                    <p><strong>ä¸­ç­‰ç›¸ä¼¼:</strong> {medium_sim_count} ä½å­¸ç”Ÿ</p>
                    <p><strong>ç„¡æ˜é¡¯ç›¸ä¼¼:</strong> {total_students - high_sim_count - medium_sim_count} ä½å­¸ç”Ÿ</p>
                </div>
                """)
                
                # æ·»åŠ ç›¸ä¼¼åº¦çŸ©é™£è¦–è¦ºåŒ–
                html_parts.append('<div class="similarity-matrix">')
                html_parts.append(f'<h3>ç›¸ä¼¼åº¦çŸ©é™£è¦–è¦ºåŒ– - é¡Œç›® {qid}</h3>')
                html_parts.append('<div class="matrix-container">')
                
                # GenAIçŸ©é™£
                genai_col = f'Q{qid}_genai_matrix'
                local_col = f'Q{qid}_local_matrix'
                
                if genai_col in merged_df.columns and pd.notna(merged_df[genai_col].iloc[0]):
                    genai_matrix_b64 = merged_df[genai_col].iloc[0]
                    html_parts.append(f"""
                    <div class="matrix-item">
                        <h4>GenAIèªç¾©ç›¸ä¼¼åº¦</h4>
                        <img src="data:image/png;base64,{genai_matrix_b64}" class="matrix-image" alt="GenAIç›¸ä¼¼åº¦çŸ©é™£">
                    </div>
                    """)
                
                if local_col in merged_df.columns and pd.notna(merged_df[local_col].iloc[0]):
                    local_matrix_b64 = merged_df[local_col].iloc[0]
                    html_parts.append(f"""
                    <div class="matrix-item">
                        <h4>éGenAIå¤šç®—æ³•ç›¸ä¼¼åº¦</h4>
                        <img src="data:image/png;base64,{local_matrix_b64}" class="matrix-image" alt="æœ¬åœ°ç›¸ä¼¼åº¦çŸ©é™£">
                    </div>
                    """)
                
                html_parts.append('</div>')  # é—œé–‰matrix-container
                html_parts.append('</div>')  # é—œé–‰similarity-matrix
    
    # ç”Ÿæˆå®Œæ•´æ•¸æ“šè¡¨æ ¼
    html_parts.append('<h2>ğŸ“‹ å®Œæ•´åˆ†ææ•¸æ“š</h2>')
    
    # å‰µå»ºç°¡åŒ–çš„è¡¨æ ¼è¦–åœ–ï¼ˆç§»é™¤çŸ©é™£æ•¸æ“šåˆ—ï¼‰
    display_df = merged_df.copy()
    matrix_cols = [col for col in display_df.columns if '_matrix' in col]
    display_df = display_df.drop(columns=matrix_cols)
    
    table_html = display_df.to_html(index=False, escape=False, classes='table table-striped')
    html_parts.append(table_html)
    
    return '\n'.join(html_parts)

def create_similarity_matrix_visualization(texts: list[str], names: list[str] = None, question_id: str = ""):
    """
    å‰µå»ºç›¸ä¼¼åº¦çŸ©é™£çš„è¦–è¦ºåŒ–åœ–è¡¨
    Returns: tuple (genai_matrix_b64, local_matrix_b64) - base64ç·¨ç¢¼çš„åœ–åƒ
    """
    if len(texts) < 2:
        return None, None
    
    # æº–å‚™å­¸ç”Ÿå§“åæ¨™ç±¤
    if names:
        labels = [name.split('(')[0].strip() if '(' in name else name[:10] for name in names]
    else:
        labels = [f"å­¸ç”Ÿ{i+1}" for i in range(len(texts))]
    
    # æˆªçŸ­æ¨™ç±¤ä»¥é©æ‡‰é¡¯ç¤º
    labels = [label[:8] + "..." if len(label) > 8 else label for label in labels]
    
    genai_matrix_b64 = None
    local_matrix_b64 = None
    
    # 1. GenAIç›¸ä¼¼åº¦çŸ©é™£ï¼ˆå¦‚æœæœ‰APIï¼‰
    if gmodel:
        try:
            # è¨ˆç®—GenAIç›¸ä¼¼åº¦çŸ©é™£
            processed_texts = [t.strip() if t and t.strip() else " " for t in texts]
            result = genai.embed_content(
                model="models/text-embedding-004", 
                content=processed_texts, 
                task_type="RETRIEVAL_DOCUMENT"
            )
            embs = result['embedding']
            genai_similarity_matrix = cosine_similarity(embs)
            
            # å‰µå»ºGenAIçŸ©é™£è¦–è¦ºåŒ–
            plt.figure(figsize=(10, 8))
            mask = np.triu(np.ones_like(genai_similarity_matrix, dtype=bool))  # åªé¡¯ç¤ºä¸‹ä¸‰è§’
            sns.heatmap(genai_similarity_matrix, 
                       mask=mask,
                       annot=True, 
                       fmt='.3f',
                       cmap='Reds',
                       xticklabels=labels,
                       yticklabels=labels,
                       cbar_kws={'label': 'ç›¸ä¼¼åº¦'})
            
            plt.title(f'Q{question_id} - GenAIèªç¾©ç›¸ä¼¼åº¦çŸ©é™£', fontsize=14, pad=20)
            plt.xlabel('å­¸ç”Ÿ', fontsize=12)  
            plt.ylabel('å­¸ç”Ÿ', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            plt.tight_layout()
            
            # è½‰ç‚ºbase64
            buffer = BytesIO()
            plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
            buffer.seek(0)
            genai_matrix_b64 = base64.b64encode(buffer.getvalue()).decode()
            plt.close()
            
        except Exception as e:
            logging.error(f"GenAIç›¸ä¼¼åº¦çŸ©é™£è¦–è¦ºåŒ–å¤±æ•—: {e}")
    
    # 2. éGenAIç›¸ä¼¼åº¦çŸ©é™£
    try:
        from alternative_similarity_methods import calculate_text_similarity_enhanced
        
        # è¨ˆç®—æœ¬åœ°ç›¸ä¼¼åº¦çŸ©é™£
        n = len(texts)
        local_similarity_matrix = np.zeros((n, n))
        
        for i in range(n):
            for j in range(n):
                if i != j and texts[i].strip() and texts[j].strip():
                    from alternative_similarity_methods import calculate_advanced_similarity
                    similarity = calculate_advanced_similarity(texts[i], texts[j])
                    local_similarity_matrix[i][j] = similarity
                elif i == j:
                    local_similarity_matrix[i][j] = 1.0
        
        # å‰µå»ºæœ¬åœ°çŸ©é™£è¦–è¦ºåŒ–
        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(local_similarity_matrix, dtype=bool))  # åªé¡¯ç¤ºä¸‹ä¸‰è§’
        sns.heatmap(local_similarity_matrix,
                   mask=mask, 
                   annot=True, 
                   fmt='.3f',
                   cmap='Blues',
                   xticklabels=labels,
                   yticklabels=labels,
                   cbar_kws={'label': 'ç›¸ä¼¼åº¦'})
        
        plt.title(f'Q{question_id} - éGenAIå¤šç®—æ³•ç›¸ä¼¼åº¦çŸ©é™£', fontsize=14, pad=20)
        plt.xlabel('å­¸ç”Ÿ', fontsize=12)
        plt.ylabel('å­¸ç”Ÿ', fontsize=12)
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # è½‰ç‚ºbase64
        buffer = BytesIO()
        plt.savefig(buffer, format='png', dpi=150, bbox_inches='tight')
        buffer.seek(0)
        local_matrix_b64 = base64.b64encode(buffer.getvalue()).decode()
        plt.close()
        
    except Exception as e:
        logging.error(f"æœ¬åœ°ç›¸ä¼¼åº¦çŸ©é™£è¦–è¦ºåŒ–å¤±æ•—: {e}")
    
    return genai_matrix_b64, local_matrix_b64