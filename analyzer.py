# analyzer.py
# æ ¸å¿ƒåˆ†æé‚è¼¯æ¨¡çµ„

import os, re, json, asyncio, logging
import pandas as pd 
import numpy as np
import google.generativeai as genai
from sklearn.metrics.pairwise import cosine_similarity
import yaml # æ–°å¢åŒ¯å…¥ yaml

# --- Gemini API è¨­å®š ---
def configure_gemini(api_key, model_name="gemini-1.5-pro-latest"):
    """è¨­å®š Gemini API é‡‘é‘°ä¸¦åˆå§‹åŒ–æ¨¡å‹"""
    global gmodel
    try:
        genai.configure(api_key=api_key)
        gmodel = genai.GenerativeModel(model_name)
        return True
    except Exception as e:
        logging.error(f"è¨­å®š Gemini API é‡‘é‘°æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

gmodel = None

# --- ä½¿ç”¨è€…å¯ä¿®æ”¹åƒæ•¸ ---
TARGET_SCORE_Q = [1, 2, 3, 4, 11]
BATCH_SIZE = 6
DO_SIMILARITY_CHECK = True

# --- è©•åˆ†æ¨™æº– (Rubrics) ---
RUBRICS = {
1: '''Rubric (10 pts total)

Section A â€“ CZ vs FZ singleâ€‘crystal Si comparison (0â€‘4 pts)
  â€¢ Clearly list â‰¥â€¯2 advantages and â‰¥â€¯2 disadvantages for **each** process  
    â€“ e.g. CZ: large diameter, cheaper / higher O contamination, lower resistivity  
    â€“ FZ: crucibleâ€‘less, ultraâ€‘high purity, high resistivity / smaller boule, costly  
  â€¢ 0.5â€¯pt per correct advantage/disadvantage, up to 4â€¯pts

Section B â€“ Channeling effect definition & impact (0â€‘3 pts)
  â€¢ Defines channeling as ions travelling along lowâ€‘index crystal axes/planes (1â€¯pt)  
  â€¢ Describes deeper projected range / dose loss / tail in dopant profile (1â€¯pt)  
  â€¢ Mentions dependence on crystal orientation/energy (1â€¯pt)

Section C â€“ Mitigation methods (0â€‘3 pts)
  Any three of the following, 1â€¯pt each (max 3â€¯pts):  
    â€“ Tilt/rotate wafer during implantation  
    â€“ Use amorphizing preâ€‘implant (e.g. Si, Ge)  
    â€“ Grow/retain surface oxide or SiN mask  
    â€“ Implant through amorphous layer (screen oxide)  
    â€“ Use random beam incidence or beam wobbling
''',
    2: '''Rubric (10 pts total) â€” Student **answers any TWO** subâ€‘problems  
Score each answered subâ€‘problem 0â€‘5 pts, keep the best two (max 10)

Subâ€‘problem 1  Massâ€‘transportâ€‘ vs. surfaceâ€‘reactionâ€‘limited CVD (0â€‘5)
  â€¢ Correct definition of each regime & rateâ€‘determining step (2â€¯pts)  
  â€¢ Describes dependence on temperature, pressure, boundary layer (1â€¯pt)  
  â€¢ Mentions impact on thickness uniformity or step coverage (1â€¯pt)  
  â€¢ Gives practical example or sketch of concentration profile (1â€¯pt)

Subâ€‘problem 2  MBE working principle (0â€‘5)
  â€¢ UHV environment & effusion cells produce atom/molecule beams (2â€¯pts)  
  â€¢ Ballistic arrival / adsorptionâ€“surface diffusionâ€“incorporation process (1â€¯pt)  
  â€¢ Inâ€‘situ monitoring (e.g. RHEED) & precise flux control (1â€¯pt)  
  â€¢ Typical growth rate (~1â€¯Âµmâ€¯hâ»Â¹) & ultraâ€‘high purity advantage (1â€¯pt)

Subâ€‘problem 3  Exceeding critical thickness in heteroepitaxy (0â€‘5)
  â€¢ Introduces misfit strain & Matthewsâ€“Blakeslee criterion (1â€¯pt)  
  â€¢ Formation of misfit dislocations / strain relaxation (2â€¯pts)  
  â€¢ Possible 3â€‘D islanding (Sâ€“K), surface roughening or cracks (1â€¯pt)  
  â€¢ Electrical/optical degradation consequence (1â€¯pt)
''',
    3: '''Rubric (10 pts total) â€” Student **answers any TWO** subâ€‘problems  
Score each answered subâ€‘problem 0â€‘5 pts, keep the best two (max 10)

Subâ€‘problem 1  Si vs GaAs band structure differences (0â€‘5)
  â€¢ Indirect (Si) vs direct (GaAs) bandgap nature & values (2â€¯pts)  
  â€¢ Conductionâ€‘band valley positions / densityâ€‘ofâ€‘states (1â€¯pt)  
  â€¢ Carrier mobility & effective mass comparison (1â€¯pt)  
  â€¢ Consequence for optoelectronic efficiency (1â€¯pt)

Subâ€‘problem 2  â€œStraddling gapâ€ heterojunction (Typeâ€‘I) (0â€‘5)
  â€¢ Correctly picks Typeâ€‘I (1â€¯pt)  
  â€¢ Conduction & valence bands of widerâ€‘gap material both higher/lower enclosing narrowâ€‘gap (2â€¯pts)  
  â€¢ Draws / verbally describes band diagram & carrier confinement (2â€¯pts)

Subâ€‘problem 3  Multijunction solarâ€‘cell spectral utilization (0â€‘5)
  â€¢ Bandgap stacking / current matching concept (2â€¯pts)  
  â€¢ Use of tunnel junctions / graded buffers (1â€¯pt)  
  â€¢ Spectrum splitting or latticeâ€‘matched material selection (1â€¯pt)  
  â€¢ Antiâ€‘reflection or lightâ€‘management strategy (1â€¯pt)
''',
    4: '''Rubric (10 pts total) â€” Student **answers any TWO** subâ€‘problems  
Score each answered subâ€‘problem 0â€‘5 pts, keep the best two (max 10)

Subâ€‘problem 1  Early challenges in GaN on sapphire (0â€‘5)
  â€¢ ~16â€¯% lattice mismatch & thermalâ€‘expansion mismatch (2â€¯pts)  
  â€¢ High threading dislocation density / cracking (1â€¯pt)  
  â€¢ Poor surface wetting, nucleation issues prior to LTâ€‘buffer invention (1â€¯pt)  
  â€¢ Impact on LED efficiency / reliability (1â€¯pt)

Subâ€‘problem 2  Difficulty of achieving pâ€‘type GaN (0â€‘5)
  â€¢ Deep acceptor level of Mg (â‰ˆ200â€¯meV) limits hole activation (2â€¯pts)  
  â€¢ H passivation forming Mgâ€“H complexes, need anneal (1â€¯pt)  
  â€¢ Compensation by native donors / defects (1â€¯pt)  
  â€¢ Historically low hole mobility / conductivity (1â€¯pt)

Subâ€‘problem 3  (D) Lower manufacturing cost? â€” critical discussion (0â€‘5)
  â€¢ States that early GaN/Sapphire actually â†‘ cost due to low yield (1â€¯pt)  
  â€¢ Explains how subsequent massâ€‘production & cheap sapphire made cost reasonable (1â€¯pt)  
  â€¢ Compares to SiC, bulk GaN or phosphorâ€‘converted alternatives (1â€¯pt)  
  â€¢ Evaluates epi reactor throughput, wafer price, device efficiency vs cost (2â€¯pts)
''',
    11: '''Rubric (10 pts total)

Partâ€¯1  Quantum confinement in 0â€‘D nanomaterials (0â€‘5)
  â€¢ Defines confinement when particle size â‰² exciton Bohr radius (1â€¯pt)  
  â€¢ Energy levels become discrete, bandgap widens with decreasing size (2â€¯pts)  
  â€¢ Mentions sizeâ€‘tunable optical emission / quantumâ€‘size effect (1â€¯pt)  
  â€¢ Gives formula E âˆ 1/LÂ² or cites typical CdSe Qâ€‘dot example (1â€¯pt)

Partâ€¯2  Si nanowires as Liâ€‘ion anode (0â€‘5)
  â€¢ Lists Si theoretical capacity â‰ˆ4200â€¯mAhâ€¯gâ»Â¹ (1â€¯pt)  
  â€¢ bulk Si issues: >300â€¯% volume expansion, pulverization, loss of contact (2â€¯pts)  
  â€¢ SiNWs accommodate strain radially / maintain electrical pathway (1â€¯pt)  
  â€¢ Large surface area for fast Li diffusion & facile SEI formation control (1â€¯pt)
''',
}

# --- Prompt æ¨¡æ¿ ---
PROMPT_TEMPLATE = """You are a meticulous graduate-level TA.
First, judge whether the following answer exhibits obvious LLM writing style (including but not limited to overly smooth transitions, template phrases like 'moreover', almost no typos).
Return an integer 'ai_risk' from 0â€‘100 (higher = more AI-like).
{grade_block}
Respond ONLY with a valid JSON object like {{"ai_risk": ..., "score": ...}}.

Question:
{question}

Answer:
{answer}
"""

def log_to_frontend(message, callback):
    """å®‰å…¨åœ°å‘¼å«å‰ç«¯æ—¥èªŒå›å‘¼å‡½å¼"""
    if callback:
        callback(message)
    else:
        print(message)

def load_exam(csv_path, log_callback):
    """å¾ CSV æª”æ¡ˆè¼‰å…¥è€ƒå·ç­”æ¡ˆ"""
    try:
        df = pd.read_csv(
            csv_path,
            encoding='utf-8',
            dtype=str,
            quotechar='"',
            escapechar='\\'
        )
        # å»é™¤æ¬„ä½åç¨±å‰å¾Œç©ºç™½ï¼Œä¸¦å°‡æ›è¡Œè½‰ç‚ºç©ºæ ¼
        df.columns = (
            df.columns
            .str.strip()
            .str.replace('\n', ' ', regex=False)
        )
        
        log_to_frontend(f"ğŸ“Š åŸå§‹æª”æ¡ˆè¼‰å…¥: {len(df)} è¡Œ", log_callback)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ 'name' æ¬„ä½
        if 'name' not in df.columns:
            log_to_frontend("âŒ æ‰¾ä¸åˆ° 'name' æ¬„ä½ï¼Œè«‹æª¢æŸ¥CSVæ ¼å¼", log_callback)
            return None, None
            
        # å»é™¤é‡è¤‡çš„å­¸ç”Ÿè¨˜éŒ„ï¼Œå„ªå…ˆä¿ç•™æœ€é«˜åˆ†æ•¸çš„è¨˜éŒ„
        original_count = len(df)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰ score æ¬„ä½ä¾†åˆ¤æ–·æœ€é«˜åˆ†
        if 'score' in df.columns:
            # å°‡åˆ†æ•¸è½‰æ›ç‚ºæ•¸å€¼å‹æ…‹
            df['score_numeric'] = pd.to_numeric(df['score'], errors='coerce').fillna(0)
            # æ ¹æ“šå§“ååˆ†çµ„ï¼Œä¿ç•™æ¯çµ„ä¸­åˆ†æ•¸æœ€é«˜çš„è¨˜éŒ„
            df = df.loc[df.groupby('name')['score_numeric'].idxmax()]
            df = df.drop(columns=['score_numeric'])  # ç§»é™¤è‡¨æ™‚æ¬„ä½
            log_to_frontend("ğŸ“Š ä¿ç•™ç­–ç•¥: æ¯ä½å­¸ç”Ÿä¿ç•™æœ€é«˜åˆ†æ•¸çš„è¨˜éŒ„", log_callback)
        else:
            # å¦‚æœæ²’æœ‰åˆ†æ•¸æ¬„ä½ï¼Œå‰‡ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç¾çš„è¨˜éŒ„
            df = df.drop_duplicates(subset=['name'], keep='first')
            log_to_frontend("ğŸ“Š ä¿ç•™ç­–ç•¥: æ¯ä½å­¸ç”Ÿä¿ç•™ç¬¬ä¸€æ¬¡è¨˜éŒ„", log_callback)
        
        deduplicated_count = len(df)
        
        if original_count != deduplicated_count:
            removed_count = original_count - deduplicated_count
            log_to_frontend(f"ğŸ”„ å»é™¤é‡è¤‡è¨˜éŒ„: {removed_count} å€‹é‡è¤‡ä½œç­”ï¼Œä¿ç•™ {deduplicated_count} ä½å­¸ç”Ÿ", log_callback)
        
        # å»é™¤å§“åç‚ºç©ºçš„è¡Œ
        df = df.dropna(subset=['name'])
        df = df[df['name'].str.strip() != '']
        final_count = len(df)
        
        if deduplicated_count != final_count:
            log_to_frontend(f"ğŸ§¹ å·²ç§»é™¤ç©ºç™½å§“å: {deduplicated_count} -> {final_count} è¡Œ", log_callback)
            
    except FileNotFoundError:
        log_to_frontend(f"âŒ æ‰¾ä¸åˆ°æŒ‡å®šçš„æª”æ¡ˆ: {csv_path}", log_callback)
        return None, None
    except Exception as e:
        log_to_frontend(f"âŒ è®€å–CSVæª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", log_callback)
        return None, None
    
    # æ‰¾åˆ°çµæ§‹æ¨™è¨˜æ¬„ä½çš„ç´¢å¼•
    try:
        attempt_idx = df.columns.get_loc('attempt')
        n_correct_idx = df.columns.get_loc('n correct')
    except KeyError as e:
        log_to_frontend(f"âŒ æ‰¾ä¸åˆ°å¿…è¦çš„æ¬„ä½: {e}ï¼Œè«‹æª¢æŸ¥CSVæ ¼å¼", log_callback)
        return None, None
    
    # è§£æattemptå’Œn correctä¹‹é–“çš„é¡Œç›®/åˆ†æ•¸é…å°
    q_map = {}
    q_counter = 1
    
    for i in range(attempt_idx + 1, n_correct_idx, 2):
        if i + 1 < n_correct_idx:  # ç¢ºä¿æœ‰é…å°çš„åˆ†æ•¸æ¬„ä½
            question_col = df.columns[i]
            score_col = df.columns[i + 1]
            
            # æª¢æŸ¥åˆ†æ•¸æ¬„ä½æ˜¯å¦ç‚ºæ•¸å€¼å‹æ…‹æˆ–åŒ…å«åˆ†æ•¸è³‡è¨Š
            if (pd.to_numeric(df[score_col], errors='coerce').notna().any() or 
                any(str(val).replace('.', '').isdigit() for val in df[score_col].dropna())):
                q_map[q_counter] = question_col
                q_counter += 1
                log_to_frontend(f"  æ‰¾åˆ°é¡Œç›® {q_counter-1}: {question_col[:50]}...", log_callback)
    
    log_to_frontend(f"âœ… æˆåŠŸè¼‰å…¥ {os.path.basename(csv_path)}ï¼Œæ‰¾åˆ° {len(df)} ä½å­¸ç”Ÿèˆ‡ {len(q_map)} é¡Œå•ç­”ã€‚", log_callback)
    return df, q_map

def calculate_similarity_flags(texts: list[str], names: list[str] = None, hi=0.85, mid=0.70, min_length=50) -> list[int]:
    """
    è¨ˆç®—ç­”æ¡ˆé–“çš„èªæ„ç›¸ä¼¼åº¦ï¼Œæª¢æ¸¬æ½›åœ¨æŠ„è¥²
    
    Args:
        texts: å­¸ç”Ÿç­”æ¡ˆåˆ—è¡¨
        names: å­¸ç”Ÿå§“ååˆ—è¡¨ï¼ˆå¯é¸ï¼‰
        hi: é«˜ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.85ï¼‰
        mid: ä¸­ç­‰ç›¸ä¼¼åº¦é–¾å€¼ï¼ˆé è¨­ 0.70ï¼‰
        min_length: æœ€å°æ–‡æœ¬é•·åº¦é–¾å€¼ï¼ˆé è¨­ 50 å­—ç¬¦ï¼‰
    
    Returns:
        list[int]: ç›¸ä¼¼åº¦æ¨™è¨˜ (0=ç„¡ç›¸ä¼¼, 1=ä¸­ç­‰ç›¸ä¼¼, 2=é«˜åº¦ç›¸ä¼¼, -1=éŒ¯èª¤)
    """
    if not DO_SIMILARITY_CHECK or len(texts) < 2:
        return [0] * len(texts)
    
    try:
        # é è™•ç†æ–‡æœ¬
        processed_texts = []
        valid_indices = []
        
        for i, text in enumerate(texts):
            if text and text.strip() and len(text.strip()) >= min_length:
                # ç°¡å–®çš„æ–‡æœ¬æ¸…ç†
                cleaned_text = text.strip()
                # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
                cleaned_text = re.sub(r'\s+', ' ', cleaned_text)
                processed_texts.append(cleaned_text)
                valid_indices.append(i)
            else:
                processed_texts.append(" ")
                valid_indices.append(i)
        
        # å¦‚æœæœ‰æ•ˆæ–‡æœ¬å°‘æ–¼ 2 å€‹ï¼Œè·³éç›¸ä¼¼åº¦æª¢æŸ¥
        valid_texts = [processed_texts[i] for i in range(len(processed_texts)) if len(processed_texts[i].strip()) >= min_length]
        if len(valid_texts) < 2:
            return [0] * len(texts)
        
        # è¨ˆç®—èªæ„åµŒå…¥
        result = genai.embed_content(
            model="models/text-embedding-004", 
            content=processed_texts, 
            task_type="RETRIEVAL_DOCUMENT"
        )
        embs = result['embedding']
        
        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        sims = cosine_similarity(embs)
        np.fill_diagonal(sims, 0)  # è¨­ç½®å°è§’ç·šç‚º 0ï¼Œé¿å…è‡ªå·±å’Œè‡ªå·±æ¯”è¼ƒ
        
        # åˆ†æç›¸ä¼¼åº¦çµæœ
        similarity_flags = []
        high_similarity_pairs = []
        
        for i in range(len(texts)):
            if len(processed_texts[i].strip()) < min_length:
                # æ–‡æœ¬éçŸ­ï¼Œä¸åƒèˆ‡ç›¸ä¼¼åº¦æª¢æŸ¥
                similarity_flags.append(0)
                continue
                
            max_sim = np.max(sims[i])
            max_sim_idx = np.argmax(sims[i])
            
            # ç¢ºå®šç›¸ä¼¼åº¦ç­‰ç´š
            if max_sim >= hi:
                flag = 2
                # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦é…å°
                if names:
                    pair_info = f"{names[i]} â†” {names[max_sim_idx]} (ç›¸ä¼¼åº¦: {max_sim:.3f})"
                else:
                    pair_info = f"å­¸ç”Ÿ {i+1} â†” å­¸ç”Ÿ {max_sim_idx+1} (ç›¸ä¼¼åº¦: {max_sim:.3f})"
                high_similarity_pairs.append(pair_info)
            elif max_sim >= mid:
                flag = 1
            else:
                flag = 0
                
            similarity_flags.append(flag)
        
        # è¨˜éŒ„é«˜ç›¸ä¼¼åº¦é…å°åˆ°æ—¥èªŒ
        if high_similarity_pairs:
            logging.warning(f"æª¢æ¸¬åˆ° {len(high_similarity_pairs)} å°é«˜ç›¸ä¼¼åº¦ç­”æ¡ˆ:")
            for pair in high_similarity_pairs:
                logging.warning(f"  ğŸš¨ {pair}")
        
        return similarity_flags
        
    except Exception as e:
        logging.error(f"åŸ·è¡Œç›¸ä¼¼åº¦è¨ˆç®—æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return [-1] * len(texts)

def get_detailed_similarity_analysis(texts: list[str], names: list[str] = None, threshold=0.70):
    """
    å–å¾—è©³ç´°çš„ç›¸ä¼¼åº¦åˆ†æå ±å‘Š
    
    Args:
        texts: å­¸ç”Ÿç­”æ¡ˆåˆ—è¡¨
        names: å­¸ç”Ÿå§“ååˆ—è¡¨ï¼ˆå¯é¸ï¼‰
        threshold: ç›¸ä¼¼åº¦é–¾å€¼
    
    Returns:
        dict: åŒ…å«ç›¸ä¼¼åº¦çŸ©é™£å’Œè©³ç´°åˆ†æçš„å­—å…¸
    """
    if not DO_SIMILARITY_CHECK or len(texts) < 2:
        return {"status": "skipped", "reason": "ç›¸ä¼¼åº¦æª¢æŸ¥å·²é—œé–‰æˆ–æ–‡æœ¬æ•¸é‡ä¸è¶³"}
    
    try:
        # é è™•ç†æ–‡æœ¬ï¼ˆèˆ‡ä¸Šé¢çš„å‡½æ•¸ä¿æŒä¸€è‡´ï¼‰
        safe_texts = [t.strip() if t and t.strip() else " " for t in texts]
        
        # è¨ˆç®—åµŒå…¥å‘é‡
        result = genai.embed_content(
            model="models/text-embedding-004", 
            content=safe_texts, 
            task_type="RETRIEVAL_DOCUMENT"
        )
        embs = result['embedding']
        
        # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
        sims = cosine_similarity(embs)
        np.fill_diagonal(sims, 0)
        
        # æ‰¾å‡ºé«˜ç›¸ä¼¼åº¦é…å°
        high_similarity_pairs = []
        for i in range(len(texts)):
            for j in range(i + 1, len(texts)):
                if sims[i][j] >= threshold:
                    student_i = names[i] if names else f"å­¸ç”Ÿ {i+1}"
                    student_j = names[j] if names else f"å­¸ç”Ÿ {j+1}"
                    high_similarity_pairs.append({
                        "student_1": student_i,
                        "student_2": student_j,
                        "similarity": float(sims[i][j]),
                        "index_1": i,
                        "index_2": j
                    })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        high_similarity_pairs.sort(key=lambda x: x["similarity"], reverse=True)
        
        return {
            "status": "completed",
            "similarity_matrix": sims.tolist(),
            "high_similarity_pairs": high_similarity_pairs,
            "total_comparisons": len(texts) * (len(texts) - 1) // 2,
            "flagged_pairs": len(high_similarity_pairs)
        }
        
    except Exception as e:
        logging.error(f"è©³ç´°ç›¸ä¼¼åº¦åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return {"status": "error", "error": str(e)}

async def gemini_eval(question: str, rubric: str, answer: str, need_score: bool) -> tuple:
    """éåŒæ­¥å‘¼å« Gemini API é€²è¡Œ AI é¢¨æ ¼åˆ†æèˆ‡è©•åˆ†"""
    if not answer or not answer.strip():
        return (0, 0 if need_score else None)
    
    if need_score:
        grade_block = f"""Then grade the answer based on this rubric (return an integer score 0-10):

{rubric}

Grade the answer objectively according to the rubric criteria."""
    else:
        grade_block = "Grading is not required for this question."
    
    prompt = PROMPT_TEMPLATE.format(question=question, answer=answer, grade_block=grade_block)
    try:
        resp = await gmodel.generate_content_async(
            prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.0, response_mime_type="application/json"),
            request_options={"timeout": 120}
        )
        if not resp.text: return (None, None)
        js = json.loads(resp.text)
        return (js.get("ai_risk"), js.get("score"))
    except Exception as e:
        logging.error(f"Gemini API å‘¼å«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return (None, None)

async def process_question(df, qid, col, log_callback):
    """è™•ç†å–®ä¸€å•é¡Œçš„æ‰€æœ‰å­¸ç”Ÿç­”æ¡ˆ"""
    log_to_frontend(f"â¡ï¸ é–‹å§‹è™•ç† Q{qid}...", log_callback)
    q_text = col.split(":", 1)[1].strip()
    need_score = qid in TARGET_SCORE_Q
    rubric = RUBRICS.get(qid, "")
    
    sub = df[["name", col]].rename(columns={col: "answer"}).fillna("")
    
    # å‚³å…¥å­¸ç”Ÿå§“åä»¥ä¾¿è¿½è¹¤ç›¸ä¼¼åº¦é…å°
    sub[f"Q{qid}_sim_flag"] = calculate_similarity_flags(
        sub["answer"].tolist(), 
        names=sub["name"].tolist()
    )
    
    out_ai, out_sc = [], []
    chunks = [sub.iloc[i:i + BATCH_SIZE] for i in range(0, len(sub), BATCH_SIZE)]
    
    for i, chunk in enumerate(chunks):
        log_to_frontend(f"    Q{qid}: è™•ç†æ‰¹æ¬¡ {i+1}/{len(chunks)}", log_callback)
        tasks = [gemini_eval(q_text, rubric, a, need_score) for a in chunk["answer"]]
        results = await asyncio.gather(*tasks)
        out_ai.extend([r[0] for r in results])
        out_sc.extend([r[1] for r in results])
        
    sub[f"Q{qid}_ai_risk"] = out_ai
    if need_score:
        sub[f"Q{qid}_score"] = out_sc
        
    return sub.drop(columns=["answer"])

async def run_analysis(api_key: str, csv_path: str, out_base_path: str, log_callback, model_name: str = "gemini-1.5-pro-latest"):
    """åŸ·è¡Œå®Œæ•´åˆ†ææµç¨‹çš„ä¸»å‡½å¼"""
    if not configure_gemini(api_key, model_name):
        log_to_frontend("âŒ API é‡‘é‘°è¨­å®šå¤±æ•—ï¼Œè«‹æª¢æŸ¥é‡‘é‘°æ˜¯å¦æ­£ç¢ºã€‚", log_callback)
        return

    log_to_frontend(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}", log_callback)

    df, qmap = load_exam(csv_path, log_callback)
    if df is None: return

    merged_df = df[["name"]].copy()
    
    for qid, col in qmap.items():
        res_df = await process_question(df, qid, col, log_callback)
        merged_df = merged_df.merge(res_df, on="name", how="left")
        
    # å®šç¾©å„ç¨®æ ¼å¼çš„è¼¸å‡ºè·¯å¾‘
    xlsx_path = f"{out_base_path}.xlsx"
    csv_path_out = f"{out_base_path}.csv"
    yaml_path = f"{out_base_path}.yaml"
    html_path = f"{out_base_path}.html"

    try:
        # å„²å­˜ç‚º Excel
        merged_df.to_excel(xlsx_path, index=False, engine='openpyxl')
        log_to_frontend(f"ğŸ‰ Excel å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{xlsx_path}", log_callback)

        # å„²å­˜ç‚º CSV
        merged_df.to_csv(csv_path_out, index=False)
        log_to_frontend(f"ğŸ‰ CSV å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{csv_path_out}", log_callback)

        # å„²å­˜ç‚º YAML
        # å°‡ DataFrame è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨ä»¥ä¾¿ YAML åºåˆ—åŒ–
        yaml_data = merged_df.to_dict(orient='records')
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(yaml_data, f, allow_unicode=True, sort_keys=False)
        log_to_frontend(f"ğŸ‰ YAML å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{yaml_path}", log_callback)

        # å„²å­˜ç‚º HTML
        # ä½¿ç”¨ DataFrame.to_html() æ–¹æ³•ï¼Œå¯ä»¥åŠ å…¥ä¸€äº›æ¨£å¼
        html_content = merged_df.to_html(index=False, escape=False, classes='table table-striped')
        # å¯ä»¥é¸æ“‡æ€§åœ°åŠ å…¥ä¸€äº›åŸºæœ¬çš„ HTML çµæ§‹å’Œ CSS æ¨£å¼
        html_output = f"""
        <html>
        <head>
            <title>åˆ†æå ±å‘Š</title>
            <style>
                body {{ font-family: sans-serif; margin: 20px; }}
                .table {{ width: 100%; border-collapse: collapse; }}
                .table th, .table td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                .table th {{ background-color: #f2f2f2; }}
                .table-striped tbody tr:nth-of-type(odd) {{ background-color: #f9f9f9; }}
            </style>
        </head>
        <body>
            <h1>åˆ†æå ±å‘Š</h1>
            {html_content}
        </body>
        </html>
        """
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_output)
        log_to_frontend(f"ğŸ‰ HTML å ±å‘Šå·²å„²å­˜è‡³ï¼š\n{html_path}", log_callback)

    except Exception as e:
        log_to_frontend(f"âŒ å„²å­˜å ±å‘Šå¤±æ•—: {e}", log_callback)